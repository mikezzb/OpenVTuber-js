{"version":3,"sources":["utils/faces.ts","utils/poses.ts","hooks/useVRM.ts","config.ts","utils/index.ts","components/VRM.tsx","components/CameraView.tsx","components/Controls.tsx","App.tsx","reportWebVitals.ts","index.tsx"],"names":["net","useVRM","loader","useRef","GLTFLoader","current","useState","vrm","setVRM","url","load","gltf","VRM","from","then","VRMUtils","removeUnnecessaryJoints","scene","rotateY","Math","PI","humanoid","getBoneNode","VRMSchema","HumanoidBoneName","LeftUpperArm","rotation","z","RightUpperArm","VIDEO_SIZE","DRAWING_COLOR","euclideanDistance","p1","p2","x","y","sqrt","drawLandmarks","ctx","r","color","beginPath","arc","fillStyle","fill","loadFacemesh","a","facemesh","mediapipeFacemesh","maxFaces","predictFace","input","estimateFaces","RIGHT_EYE_POINTS","LEFT_EYE_POINTS","LIPS_OPEN_SAMPLES","LIPS_OPEN_SAMPLES_LENGTH","length","face2quaternion","annotations","faces","silhouette","x1","THREE","fromArray","x2","y1","y2","xaxis","sub","normalize","yaxis","zaxis","crossVectors","mat","makeBasis","premultiply","makeRotationZ","setFromRotationMatrix","lipsOpenFactor","lowerKey","upperKey","samples","samplesLength","sum","forEach","index","lower","upper","getOpenFactor","getEyesOpen","scaledMesh","leftHorizDistance","leftVertDistance","right","left","FACES","faceGeo","drawPath","points","closePath","region","Path2D","moveTo","i","point","lineTo","strokeStyle","stroke","drawMesh","predictions","prediction","keypoints","map","loadPosenet","posenet","inputResolution","height","width","architecture","outputStride","predictPose","estimateSinglePose","getAngle","atan2","drawKeypoints","poseParts","keypoint","score","position","part","drawConnectors","scale","lineWidth","drawLine","webcamRef","meshCanvasRef","prevState","face","angle","useFrame","delta","clock","mouse","video","readyState","Head","quaternion","slerp","blendShapeProxy","setValue","BlendShapePresetName","A","eyesOpen","BlinkL","BlinkR","videoWidth","videoHeight","getContext","leftShoulder","rightShoulder","Spine","leftElbow","leftWrist","RightLowerArm","rightElbow","rightWrist","LeftLowerArm","update","object","CameraView","onUserMediaError","e","alert","audio","className","ref","extend","OrbitControls","Controls","controls","useThree","camera","gl","args","domElement","target","Vector3","screenSpacePanning","App","loadVRM","init","useEffect","style","pixelRatio","fov","near","far","zoom","attach","reportWebVitals","onPerfEntry","Function","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"ogUAWIA,ECLAA,E,qGCuBWC,EAvBA,WACb,IAAiBC,EAAWC,iBAAO,IAAIC,KAA/BC,QACR,EAAsBC,mBAAqB,MAA3C,mBAAOC,EAAP,KAAYC,EAAZ,KAkBA,MAAO,CAACD,EAhBQ,SAACE,GACfP,EAAOQ,KAAKD,GAAK,SAAAE,GACfC,IAAIC,KAAKF,GAAMG,MAAK,SAAAP,GAClBQ,IAASC,wBAAwBL,EAAKM,OACtCV,EAAIU,MAAMC,QAAQC,KAAKC,IACvBb,EAAIc,SAASC,YACXC,IAAUC,iBAAiBC,cAC3BC,SAASC,EAbO,IAclBpB,EAAIc,SAASC,YACXC,IAAUC,iBAAiBI,eAC3BF,SAASC,GAhBO,IAiBlBnB,EAAOD,Y,kCCnBFsB,EACJ,IADIA,EAEH,IAGGC,EAAgB,OCDhBC,EAAoB,SAACC,EAAIC,GACpC,IAAMC,EAAID,EAAG,GAAKD,EAAG,GACfG,EAAIF,EAAG,GAAKD,EAAG,GACfL,EAAIM,EAAG,GAAKD,EAAG,GACrB,OAAOb,KAAKiB,KAAKF,EAAIA,EAAIC,EAAIA,EAAIR,EAAIA,IAqB1BU,EAAgB,SAACC,EAAKH,EAAGD,GAAqC,IAAlCK,EAAiC,uDAA7B,EAAGC,EAA0B,uDAAlBV,EACtDQ,EAAIG,YACJH,EAAII,IAAIR,EAAGC,EAAGI,EAAG,EAAG,EAAIpB,KAAKC,IAC7BkB,EAAIK,UAAYH,EAChBF,EAAIM,QJtBOC,EAAY,uCAAG,sBAAAC,EAAA,sEACdC,IAAcA,IAA2BC,kBAAmB,CACtEC,SAAU,IAFc,OAC1BjD,EAD0B,kDAAH,qDAMZkD,EAAW,uCAAG,WAAOC,GAAP,SAAAL,EAAA,0DACrB9C,EADqB,gCAEVA,EAAIoD,cAAc,CAAED,UAFV,mFAAH,sDAQlBE,EAAmB,CAAC,IAAK,IAAK,IAAK,KACnCC,EAAkB,CAAC,IAAK,GAAI,IAAK,KAEjCC,EAAoB,CAAC,EAAG,EAAG,EAAG,GAC9BC,EAA2BD,EAAkBE,OAGtCC,EAAkB,SAAAC,GAC7B,IAAMC,EAAQD,EAAYE,WACpBC,GAAK,IAAIC,WAAgBC,UAAUJ,EAAM,IACzCK,GAAK,IAAIF,WAAgBC,UAAUJ,EAAM,KACzCM,GAAK,IAAIH,WAAgBC,UAAUJ,EAAM,KACzCO,GAAK,IAAIJ,WAAgBC,UAAUJ,EAAM,IACzCQ,EAAQH,EAAGI,IAAIP,GAAIQ,YACnBC,EAAQJ,EAAGE,IAAIH,GAAII,YACnBE,GAAQ,IAAIT,WAAgBU,aAAaL,EAAOG,GAChDG,GAAM,IAAIX,WACbY,UAAUP,EAAOG,EAAOC,GACxBI,aAAY,IAAIb,WAAgBc,cAAc1D,KAAKC,KACtD,OAAO,IAAI2C,cAAmBe,sBAAsBJ,IAGzCK,EAAiB,SAAApB,GAAW,OIpCZ,SAC3BA,EACAqB,EACAC,EACAC,EACAC,GAEA,IAAIC,EAAM,EAMV,OALAF,EAAQG,SAAQ,SAAAC,GACd,IAAMC,EAAQ5B,EAAYqB,GAAUM,GAlBxB,GAmBNE,EAAQ7B,EAAYsB,GAAUK,GAnBxB,GAoBZF,GAAOG,EAAQC,KAEVJ,EAAMD,EJwBbM,CACE9B,EACA,iBACA,iBACAJ,EACAC,IAQSkC,EAAc,SAACC,GAC1B,IAAMC,EAAoB7D,EACxB4D,EAAWrC,EAAgB,IAC3BqC,EAAWrC,EAAgB,KAEvBuC,EAAmB9D,EACvB4D,EAAWrC,EAAgB,IAC3BqC,EAAWrC,EAAgB,KAY7B,MAAO,CACLwC,MAXyB/D,EACzB4D,EAAWtC,EAAiB,IAC5BsC,EAAWtC,EAAiB,MAOgB,EALpBtB,EACxB4D,EAAWtC,EAAiB,IAC5BsC,EAAWtC,EAAiB,MA9CL,GAoDvB0C,KAJqBH,GAAqB,EAAIC,GAhDvB,KA2DdG,EAAQC,EAEfC,EAAW,SAAC5D,EAAK6D,EAAQC,GAC7B,IAAMC,EAAS,IAAIC,OACnBD,EAAOE,OAAOJ,EAAO,GAAG,GAAIA,EAAO,GAAG,IACtC,IAAK,IAAIK,EAAI,EAAGA,EAAIL,EAAO1C,OAAQ+C,IAAK,CACtC,IAAMC,EAAQN,EAAOK,GACrBH,EAAOK,OAAOD,EAAM,GAAIA,EAAM,IAE5BL,GACFC,EAAOD,YAET9D,EAAIqE,YAAc,OAClBrE,EAAIsE,OAAOP,IAGAQ,EAAW,SAACC,EAAaxE,IACrB,OAAXwE,QAAW,IAAXA,OAAA,EAAAA,EAAarD,QAAS,GACxBqD,EAAYzB,SAAQ,SAAA0B,GAElB,IADA,IAAMC,EAAYD,EAAWpB,WACpBa,EAAI,EAAGA,EAAIR,EAAMvC,OAAS,EAAG+C,IAAK,CACzC,IAAML,EAAS,CAACH,EAAU,EAAJQ,GAAQR,EAAU,EAAJQ,EAAQ,GAAIR,EAAU,EAAJQ,EAAQ,IAAIS,KAChE,SAAA3B,GAAK,OAAI0B,EAAU1B,MAErBY,EAAS5D,EAAK6D,GAAQ,GAExBa,EAAU3B,SAAQ,SAAAoB,GAChBpE,EAAcC,EAAKmE,EAAM,GAAIA,EAAM,GAAI,U,SC3GlCS,EAAW,uCAAG,sBAAApE,EAAA,sEACbqE,IAAa,CACvBC,gBAAiB,CACfC,OALQ,EAKAxF,EACRyF,MANQ,EAMDzF,GAET0F,aAAc,WACdC,aAAc,KAPS,OACzBxH,EADyB,kDAAH,qDAWXyH,EAAW,uCAAG,WAAOtE,GAAP,SAAAL,EAAA,0DACrB9C,EADqB,gCAEVA,EAAI0H,mBAAmBvE,GAFb,mFAAH,sDAQXwE,EAAW,SAAC1F,EAAID,GAC3B,OAAOb,KAAKyG,MAAM3F,EAAGE,EAAIH,EAAGG,EAAGF,EAAGC,EAAIF,EAAGE,IAK9B2F,EAAgB,SAACb,EAA+B1E,GAC3D,IAAMwF,EAAY,GAWlB,OAVAd,EAAU3B,SAAQ,SAAA0C,GAChB,GAAIA,EAASC,MA/BM,GA+BkB,CACnC,MAAiBD,EAASE,SAAlB9F,EAAR,EAAQA,EAAGD,EAAX,EAAWA,EACX4F,EAAUC,EAASG,MAAQ,CACzBhG,EAAGL,EAAmBK,EACtBC,EAAGN,EAAoBM,GAEzBE,EAAcC,EApCN,EAoCWH,EApCX,EAoCsBD,OAG3B4F,GAGIK,EAAiB,SAACnB,EAA+B1E,GAC5D6E,IAA6BH,EA5CR,IA4CmC3B,SAAQ,SAAAc,IGd1C,SACtB7D,EADsB,KAOlB,IALC4B,EAKF,EALD/B,EAAU2B,EAKT,EALM5B,EACJiC,EAIF,EAJDhC,EAAU8B,EAIT,EAJM/B,EACToF,EAGG,uDAHK,EACR9E,EAEG,uDAFKV,EACRsG,EACG,uDADK,EAER9F,EAAIG,YACJH,EAAIiE,OAAOzC,EAAKsE,EAAOlE,EAAKkE,GAC5B9F,EAAIoE,OAAOzC,EAAKmE,EAAOjE,EAAKiE,GAC5B9F,EAAI+F,UAAYf,EAChBhF,EAAIqE,YAAcnE,EAClBF,EAAIsE,SHEF0B,CAAShG,EAAK6D,EAAO,GAAG8B,SAAU9B,EAAO,GAAG8B,SAAU,EAAG,MA5C/C,O,QIsICrH,EAtHQ,SAAC,GAAuC,IAArCL,EAAoC,EAApCA,IAAKgI,EAA+B,EAA/BA,UAAWC,EAAoB,EAApBA,cAClCC,EAAYtI,iBAGf,CAAEuI,KAAM,GAAIC,MAAO,KA+GtB,OA7GAC,YAAQ,uCAAC,aAAyBC,GAAzB,6CAAA/F,EAAA,2DAASgG,MAAT,EAAgBC,OACnBxI,KAAG,OAAIgI,QAAJ,IAAIA,OAAJ,EAAIA,EAAWlI,UAAkD,IAAvCkI,EAAUlI,QAAQ2I,MAAMC,WADlD,iCAGqB/F,EAAYqF,EAAUlI,QAAQ2I,OAHnD,cAGClC,EAHD,UAIU,UAAKA,EAAY,UAAjB,aAAI,EAAyBnD,eACpCA,EADiD,UAClCmD,EAAY,UADsB,aACnC,EAAyBnD,YAE7CpD,EAAIc,SACDC,YAAYC,IAAUC,iBAAiB0H,MACvCC,WAAWC,MAAM1F,EAAgBC,GAAc,IAElDpD,EAAI8I,gBAAgBC,SAClB/H,IAAUgI,qBAAqBC,EAC/BzE,EAAepB,IAGX8F,EAAW/D,EAAYoB,EAAY,GAAGnB,YAC5CpF,EAAI8I,gBAAgBC,SAClB/H,IAAUgI,qBAAqBG,OAC/BD,EAAS1D,KAAO,EAAI,GAEtBxF,EAAI8I,gBAAgBC,SAClB/H,IAAUgI,qBAAqBI,OAC/BF,EAAS3D,MAAQ,EAAI,IAGnB8D,EAAarB,EAAUlI,QAAQ2I,MAAMY,WACrCC,EAActB,EAAUlI,QAAQ2I,MAAMa,YAC5CrB,EAAcnI,QAAQiH,MAAQsC,EAC9BpB,EAAcnI,QAAQgH,OAASwC,EACzBvH,EAAMkG,EAAcnI,QAAQyJ,WAAW,MAC7CjD,EAASC,EAAaxE,GA/BjB,UA4CwBmF,EAAYc,EAAUlI,QAAQ2I,OA5CtD,kDA4CiE,GA5CjE,gBA4CGhC,EA5CH,EA4CGA,aAEAc,EAAiBD,EAAcb,EAAW1E,GAChD6F,EAAenB,EAAW1E,GAEtBwF,EAAUiC,cAAgBjC,EAAUkC,eAExB,QADVrB,EAAQhB,EAASG,EAAUkC,cAAelC,EAAUiC,iBAEtDpB,GAASA,EACTF,EAAUpI,QAAQsI,MAAMsB,MAAQtB,EAChCpI,EAAIc,SAASC,YACXC,IAAUC,iBAAiByI,OAC3BvI,SAASC,EAAIgH,GAGfb,EAAUiC,cAAgBjC,EAAUoC,WAExB,QADVvB,EAAQhB,EAASG,EAAUoC,UAAWpC,EAAUiC,iBAElDpB,EAAQxH,KAAKC,GAAKuH,EAClBF,EAAUpI,QAAQsI,MAAM/G,cAAgB+G,EACxCA,GAAiBF,EAAUpI,QAAQsI,MAAMsB,OAAS,EAClD1J,EAAIc,SAASC,YACXC,IAAUC,iBAAiBI,eAC3BF,SAASC,EAAIgH,GAGfb,EAAUqC,WAAarC,EAAUoC,WAErB,QADVvB,EAAQhB,EAASG,EAAUqC,UAAWrC,EAAUoC,cAElDvB,EAAQxH,KAAKC,GAAKuH,EAClBF,EAAUpI,QAAQsI,MAAMyB,cAAgBzB,EACxCA,GAAiBF,EAAUpI,QAAQsI,MAAM/G,eAAiB,EAC1DrB,EAAIc,SAASC,YACXC,IAAUC,iBAAiB4I,eAC3B1I,SAASC,EAAIgH,GAGfb,EAAUkC,eAAiBlC,EAAUuC,YAEzB,QADV1B,EAAQhB,EAASG,EAAUuC,WAAYvC,EAAUkC,kBAEnDrB,IAAiB,EACjBF,EAAUpI,QAAQsI,MAAMlH,aAAekH,EACvCA,GAAiBF,EAAUpI,QAAQsI,MAAMsB,OAAS,EAClD1J,EAAIc,SAASC,YACXC,IAAUC,iBAAiBC,cAC3BC,SAASC,EAAIgH,GAGfb,EAAUwC,YAAcxC,EAAUuC,YAEtB,QADV1B,EAAQhB,EAASG,EAAUwC,WAAYxC,EAAUuC,eAEnD1B,GAASA,EACTF,EAAUpI,QAAQsI,MAAM4B,aAAe5B,EACvCA,GAAiBF,EAAUpI,QAAQsI,MAAMlH,cAAgB,EACzDlB,EAAIc,SAASC,YACXC,IAAUC,iBAAiB+I,cAC3B7I,SAASC,EAAIgH,IAKrBpI,EAAIiK,OAAO3B,GAzGN,4CAAD,yDA6GDtI,GAAO,2BAAWkK,OAAQlK,EAAIU,S,2BC5GxByJ,G,OArBe,SAAC,GAAkC,IAAhCnC,EAA+B,EAA/BA,UAAWC,EAAoB,EAApBA,cAC1C,OACE,qCACE,cAAC,IAAD,CACEmC,iBAAkB,SAAAC,GAAC,OAAIC,MAAMD,IAC7BE,OAAO,EACPC,UAAU,eACVC,IAAKzC,EACLjB,MAAOzF,EACPwF,OAAQxF,IAEV,wBACEyF,MAAOzF,EACPwF,OAAQxF,EACRkJ,UAAU,kBACVC,IAAKxC,S,SCrBbyC,YAAO,CAAEC,oBAaT,IAgBeC,EAhBY,WACzB,IAAMC,EAAWjL,iBAAsB,MACvC,EAAuBkL,cAAfC,EAAR,EAAQA,OAAQC,EAAhB,EAAgBA,GAIhB,OAFA3C,aAAS,kCAAMwC,EAAS/K,eAAf,aAAM,EAAkBmK,YAG/B,+BACEQ,IAAKI,EACLI,KAAM,CAACF,EAAQC,EAAGE,YAClBC,OAAQ,IAAIC,UAAQ,EAAG,EAAG,GAC1BC,oBAAkB,KC0BTC,EA7CC,WACd,IAAMtD,EAAYpI,iBAAO,MACnBqI,EAAgBrI,iBAAO,MAC7B,EAAuBF,IAAvB,mBAAOM,EAAP,KAAYuL,EAAZ,KAEMC,EAAI,uCAAG,sBAAAjJ,EAAA,sDACXgJ,EACE,iGAEFjJ,IACAqE,IALW,2CAAH,qDAaV,OAJA8E,qBAAU,WACRD,MACC,IAGD,gCACE,eAAC,IAAD,CACEE,MAAO,CACL5E,OAAQ,QACRC,MAAO,SAET4E,WAAY,EACZnB,UAAU,eACVO,OAAQ,CACNa,IAAK,GACLC,KAAM,GACNC,IAAK,GACLpE,SAAU,CAAC,EAAG,EAAG,GACjBqE,KAAM,KAZV,UAeE,uBAAOC,OAAO,aAAaf,KAAM,CAAC,EAAG,EAAG,KACxC,qCACA,cAAC,EAAD,CAAKjD,UAAWA,EAAWC,cAAeA,EAAejI,IAAKA,IAC9D,cAAC,EAAD,OAEF,cAAC,EAAD,CAAYgI,UAAWA,EAAWC,cAAeA,QCpCxCgE,EAZS,SAACC,GACnBA,GAAeA,aAAuBC,UACxC,8BAAqB5L,MAAK,YAAkD,IAA/C6L,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOF,GACPG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAQN,OCHdO,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1BZ,M","file":"static/js/main.76d7d469.chunk.js","sourcesContent":["import '@tensorflow/tfjs-backend-webgl';\nimport * as facemesh from '@tensorflow-models/face-landmarks-detection';\nimport { MediaPipeFaceMesh } from '@tensorflow-models/face-landmarks-detection/dist/mediapipe-facemesh';\n\nimport * as THREE from 'three';\nimport { Coord3D } from '@tensorflow-models/face-landmarks-detection/dist/mediapipe-facemesh/util';\nimport faceGeo from './faceGeo.json';\nimport { drawLandmarks, euclideanDistance, getOpenFactor } from '.';\n\n// MODEL\n\nlet net: MediaPipeFaceMesh;\n\nexport const loadFacemesh = async () => {\n  net = await facemesh.load(facemesh.SupportedPackages.mediapipeFacemesh, {\n    maxFaces: 1,\n  });\n};\n\nexport const predictFace = async (input: HTMLVideoElement) => {\n  if (net) {\n    return await net.estimateFaces({ input });\n  }\n};\n\n// VRM\n\nconst RIGHT_EYE_POINTS = [263, 362, 386, 374];\nconst LEFT_EYE_POINTS = [133, 33, 159, 145];\n\nconst LIPS_OPEN_SAMPLES = [0, 3, 6, 9];\nconst LIPS_OPEN_SAMPLES_LENGTH = LIPS_OPEN_SAMPLES.length;\nconst CLOSE_EYE_BOUNDARY = 0.1;\n\nexport const face2quaternion = annotations => {\n  const faces = annotations.silhouette;\n  const x1 = new THREE.Vector3().fromArray(faces[9]);\n  const x2 = new THREE.Vector3().fromArray(faces[27]);\n  const y1 = new THREE.Vector3().fromArray(faces[18]);\n  const y2 = new THREE.Vector3().fromArray(faces[0]);\n  const xaxis = x2.sub(x1).normalize();\n  const yaxis = y2.sub(y1).normalize();\n  const zaxis = new THREE.Vector3().crossVectors(xaxis, yaxis);\n  const mat = new THREE.Matrix4()\n    .makeBasis(xaxis, yaxis, zaxis)\n    .premultiply(new THREE.Matrix4().makeRotationZ(Math.PI));\n  return new THREE.Quaternion().setFromRotationMatrix(mat);\n};\n\nexport const lipsOpenFactor = annotations =>\n  getOpenFactor(\n    annotations,\n    'lipsLowerInner',\n    'lipsUpperInner',\n    LIPS_OPEN_SAMPLES,\n    LIPS_OPEN_SAMPLES_LENGTH\n  );\n\ntype EyesOpen = {\n  left: boolean;\n  right: boolean;\n};\n\nexport const getEyesOpen = (scaledMesh: Coord3D[]): EyesOpen => {\n  const leftHorizDistance = euclideanDistance(\n    scaledMesh[LEFT_EYE_POINTS[2]],\n    scaledMesh[LEFT_EYE_POINTS[3]]\n  );\n  const leftVertDistance = euclideanDistance(\n    scaledMesh[LEFT_EYE_POINTS[0]],\n    scaledMesh[LEFT_EYE_POINTS[1]]\n  );\n  const rightHorizDistance = euclideanDistance(\n    scaledMesh[RIGHT_EYE_POINTS[2]],\n    scaledMesh[RIGHT_EYE_POINTS[3]]\n  );\n  const rightVertDistance = euclideanDistance(\n    scaledMesh[RIGHT_EYE_POINTS[0]],\n    scaledMesh[RIGHT_EYE_POINTS[1]]\n  );\n  const leftOpenFactor = leftHorizDistance / (2 * leftVertDistance);\n  const rightOpenFactor = rightHorizDistance / (2 * rightVertDistance);\n  return {\n    right: rightOpenFactor < CLOSE_EYE_BOUNDARY,\n    left: leftOpenFactor < CLOSE_EYE_BOUNDARY,\n  };\n};\n\n// CANVAS\n\n// https://github.com/spite/FaceMeshFaceGeometry/blob/master/js/geometry.js\nexport const FACES = faceGeo;\n\nconst drawPath = (ctx, points, closePath) => {\n  const region = new Path2D();\n  region.moveTo(points[0][0], points[0][1]);\n  for (let i = 1; i < points.length; i++) {\n    const point = points[i];\n    region.lineTo(point[0], point[1]);\n  }\n  if (closePath) {\n    region.closePath();\n  }\n  ctx.strokeStyle = 'grey';\n  ctx.stroke(region);\n};\n\nexport const drawMesh = (predictions, ctx) => {\n  if (predictions?.length > 0) {\n    predictions.forEach(prediction => {\n      const keypoints = prediction.scaledMesh;\n      for (let i = 0; i < FACES.length / 3; i++) {\n        const points = [FACES[i * 3], FACES[i * 3 + 1], FACES[i * 3 + 2]].map(\n          index => keypoints[index]\n        );\n        drawPath(ctx, points, true);\n      }\n      keypoints.forEach(point => {\n        drawLandmarks(ctx, point[1], point[0], 1);\n      });\n    });\n  }\n};\n","import * as posenet from '@tensorflow-models/posenet';\nimport { VIDEO_SIZE } from '../config';\nimport { drawLandmarks, drawLine } from '.';\n\n// MODEL\n\nlet net: posenet.PoseNet;\n\nconst ADOPTION_POINT = 0.8;\nconst SCALE = 2;\n\nexport const loadPosenet = async () => {\n  net = await posenet.load({\n    inputResolution: {\n      height: VIDEO_SIZE.height * SCALE,\n      width: VIDEO_SIZE.width * SCALE,\n    },\n    architecture: 'ResNet50',\n    outputStride: 32,\n  });\n};\n\nexport const predictPose = async (input: HTMLVideoElement) => {\n  if (net) {\n    return await net.estimateSinglePose(input);\n  }\n};\n\n// VRM\n\nexport const getAngle = (p2, p1) => {\n  return Math.atan2(p2.y - p1.y, p2.x - p1.x);\n};\n\n// CANVAS\n\nexport const drawKeypoints = (keypoints: posenet.Keypoint[], ctx) => {\n  const poseParts = {};\n  keypoints.forEach(keypoint => {\n    if (keypoint.score > ADOPTION_POINT) {\n      const { y, x } = keypoint.position;\n      poseParts[keypoint.part] = {\n        x: VIDEO_SIZE.width - x,\n        y: VIDEO_SIZE.height - y,\n      };\n      drawLandmarks(ctx, y * SCALE, x * SCALE);\n    }\n  });\n  return poseParts;\n};\n\nexport const drawConnectors = (keypoints: posenet.Keypoint[], ctx) => {\n  posenet.getAdjacentKeyPoints(keypoints, ADOPTION_POINT).forEach(points => {\n    drawLine(ctx, points[0].position, points[1].position, 1, 'red', SCALE);\n  });\n};\n","import { VRM, VRMSchema, VRMUtils } from '@pixiv/three-vrm';\nimport { useRef, useState } from 'react';\nimport { GLTFLoader } from 'three/examples/jsm/loaders/GLTFLoader';\n\nconst ARM_ROTATE_DEGREE = 1.2;\n\nconst useVRM = (): [VRM | null, (_: string) => void] => {\n  const { current: loader } = useRef(new GLTFLoader());\n  const [vrm, setVRM] = useState<VRM | null>(null);\n\n  const loadVRM = (url: string): void => {\n    loader.load(url, gltf => {\n      VRM.from(gltf).then(vrm => {\n        VRMUtils.removeUnnecessaryJoints(gltf.scene);\n        vrm.scene.rotateY(Math.PI);\n        vrm.humanoid.getBoneNode(\n          VRMSchema.HumanoidBoneName.LeftUpperArm\n        ).rotation.z = ARM_ROTATE_DEGREE;\n        vrm.humanoid.getBoneNode(\n          VRMSchema.HumanoidBoneName.RightUpperArm\n        ).rotation.z = -ARM_ROTATE_DEGREE;\n        setVRM(vrm);\n      });\n    });\n  };\n\n  return [vrm, loadVRM];\n};\n\nexport default useVRM;\n","export const DETECT_INTERVAL = 10;\n\nexport const VIDEO_SIZE = {\n  width: 320,\n  height: 240,\n};\n\nexport const DRAWING_COLOR = 'aqua';\n","import { DRAWING_COLOR } from '../config';\n\n// THREE\n\nconst Z_INDEX = 2;\n\nexport const euclideanDistance = (p1, p2) => {\n  const x = p2[0] - p1[0];\n  const y = p2[1] - p1[1];\n  const z = p2[2] - p1[2];\n  return Math.sqrt(x * x + y * y + z * z);\n};\n\nexport const getOpenFactor = (\n  annotations,\n  lowerKey: string,\n  upperKey: string,\n  samples: number[],\n  samplesLength: number\n) => {\n  let sum = 0;\n  samples.forEach(index => {\n    const lower = annotations[lowerKey][index][Z_INDEX];\n    const upper = annotations[upperKey][index][Z_INDEX];\n    sum += lower - upper;\n  });\n  return sum / samplesLength;\n};\n\n// CANVAS\n\nexport const drawLandmarks = (ctx, y, x, r = 3, color = DRAWING_COLOR) => {\n  ctx.beginPath();\n  ctx.arc(x, y, r, 0, 2 * Math.PI);\n  ctx.fillStyle = color;\n  ctx.fill();\n};\n\nexport const drawLine = (\n  ctx,\n  { y: y1, x: x1 },\n  { y: y2, x: x2 },\n  width = 1,\n  color = DRAWING_COLOR,\n  scale = 1\n) => {\n  ctx.beginPath();\n  ctx.moveTo(x1 * scale, y1 * scale);\n  ctx.lineTo(x2 * scale, y2 * scale);\n  ctx.lineWidth = width;\n  ctx.strokeStyle = color;\n  ctx.stroke();\n};\n","import { VRM as ThreeVRM, VRMSchema } from '@pixiv/three-vrm';\nimport { RefObject, useRef, FC } from 'react';\nimport { useFrame } from 'react-three-fiber';\nimport { AnnotatedPrediction } from '@tensorflow-models/face-landmarks-detection/dist/mediapipe-facemesh';\nimport Webcam from 'react-webcam';\nimport {\n  face2quaternion,\n  lipsOpenFactor,\n  drawMesh,\n  predictFace,\n  getEyesOpen,\n} from '../utils/faces';\nimport {\n  drawConnectors,\n  drawKeypoints,\n  getAngle,\n  predictPose,\n} from '../utils/poses';\n\ntype Props = {\n  vrm: ThreeVRM | null;\n  webcamRef: RefObject<Webcam>;\n  meshCanvasRef: RefObject<HTMLCanvasElement>;\n};\n\nconst VRM: FC<Props> = ({ vrm, webcamRef, meshCanvasRef }) => {\n  const prevState = useRef<{\n    face: AnnotatedPrediction[];\n    angle: Record<string, any>;\n  }>({ face: [], angle: {} });\n\n  useFrame(async ({ clock, mouse }, delta) => {\n    if (vrm && webcamRef?.current && webcamRef.current.video.readyState === 4) {\n      // Face Handling\n      const predictions = await predictFace(webcamRef.current.video);\n      if (predictions && (predictions[0] as any)?.annotations) {\n        const annotations = (predictions[0] as any)?.annotations;\n        // Head\n        vrm.humanoid\n          .getBoneNode(VRMSchema.HumanoidBoneName.Head)\n          .quaternion.slerp(face2quaternion(annotations), 0.1);\n        // Lips\n        vrm.blendShapeProxy.setValue(\n          VRMSchema.BlendShapePresetName.A,\n          lipsOpenFactor(annotations)\n        );\n        // Eyes\n        const eyesOpen = getEyesOpen(predictions[0].scaledMesh as any);\n        vrm.blendShapeProxy.setValue(\n          VRMSchema.BlendShapePresetName.BlinkL,\n          eyesOpen.left ? 1 : 0\n        );\n        vrm.blendShapeProxy.setValue(\n          VRMSchema.BlendShapePresetName.BlinkR,\n          eyesOpen.right ? 1 : 0\n        );\n      }\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight;\n      meshCanvasRef.current.width = videoWidth;\n      meshCanvasRef.current.height = videoHeight;\n      const ctx = meshCanvasRef.current.getContext('2d');\n      drawMesh(predictions, ctx);\n\n      // Hand Handling (DISABLED DUE TO ISSUE: https://github.com/tensorflow/tfjs/issues/2942)\n      /*\n      const handPredictions = await predictHands(webcamRef.current.video);\n      if (handPredictions) {\n        drawHands(handPredictions, ctx);\n      }\n      */\n\n      /* Pose Handling\n       * https://gist.github.com/atskimura/198e558e0eff94774892d4ee9e22f98e\n       */\n      const { keypoints } = (await predictPose(webcamRef.current.video)) || {};\n      if (keypoints) {\n        const poseParts: any = drawKeypoints(keypoints, ctx);\n        drawConnectors(keypoints, ctx);\n\n        if (poseParts.leftShoulder && poseParts.rightShoulder) {\n          let angle = getAngle(poseParts.rightShoulder, poseParts.leftShoulder);\n          if (angle !== null) {\n            angle = -angle;\n            prevState.current.angle.Spine = angle;\n            vrm.humanoid.getBoneNode(\n              VRMSchema.HumanoidBoneName.Spine\n            ).rotation.z = angle;\n          }\n        }\n        if (poseParts.leftShoulder && poseParts.leftElbow) {\n          let angle = getAngle(poseParts.leftElbow, poseParts.leftShoulder);\n          if (angle !== null) {\n            angle = Math.PI - angle;\n            prevState.current.angle.RightUpperArm = angle;\n            angle = angle - (prevState.current.angle.Spine || 0);\n            vrm.humanoid.getBoneNode(\n              VRMSchema.HumanoidBoneName.RightUpperArm\n            ).rotation.z = angle;\n          }\n        }\n        if (poseParts.leftWrist && poseParts.leftElbow) {\n          let angle = getAngle(poseParts.leftWrist, poseParts.leftElbow);\n          if (angle !== null) {\n            angle = Math.PI - angle;\n            prevState.current.angle.RightLowerArm = angle;\n            angle = angle - (prevState.current.angle.RightUpperArm || 0);\n            vrm.humanoid.getBoneNode(\n              VRMSchema.HumanoidBoneName.RightLowerArm\n            ).rotation.z = angle;\n          }\n        }\n        if (poseParts.rightShoulder && poseParts.rightElbow) {\n          let angle = getAngle(poseParts.rightElbow, poseParts.rightShoulder);\n          if (angle !== null) {\n            angle = angle * -1;\n            prevState.current.angle.LeftUpperArm = angle;\n            angle = angle - (prevState.current.angle.Spine || 0);\n            vrm.humanoid.getBoneNode(\n              VRMSchema.HumanoidBoneName.LeftUpperArm\n            ).rotation.z = angle;\n          }\n        }\n        if (poseParts.rightWrist && poseParts.rightElbow) {\n          let angle = getAngle(poseParts.rightWrist, poseParts.rightElbow);\n          if (angle !== null) {\n            angle = -angle;\n            prevState.current.angle.LeftLowerArm = angle;\n            angle = angle - (prevState.current.angle.LeftUpperArm || 0);\n            vrm.humanoid.getBoneNode(\n              VRMSchema.HumanoidBoneName.LeftLowerArm\n            ).rotation.z = angle;\n          }\n        }\n      }\n\n      vrm.update(delta);\n    }\n  });\n\n  return vrm && <primitive object={vrm.scene} />;\n};\n\nexport default VRM;\n","import { FC, RefObject } from 'react';\nimport '@tensorflow/tfjs-backend-webgl';\nimport Webcam from 'react-webcam';\nimport './CameraView.scss';\nimport { VIDEO_SIZE } from '../config';\n\ntype Props = {\n  webcamRef: RefObject<Webcam>;\n  meshCanvasRef: RefObject<HTMLCanvasElement>;\n};\n\nconst CameraView: FC<Props> = ({ webcamRef, meshCanvasRef }) => {\n  return (\n    <>\n      <Webcam\n        onUserMediaError={e => alert(e)}\n        audio={false}\n        className=\"webcam-video\"\n        ref={webcamRef}\n        width={VIDEO_SIZE.width}\n        height={VIDEO_SIZE.height}\n      />\n      <canvas\n        width={VIDEO_SIZE.width}\n        height={VIDEO_SIZE.height}\n        className=\"facemesh-canvas\"\n        ref={meshCanvasRef}\n      />\n    </>\n  );\n};\n\nexport default CameraView;\n","import React, { useRef } from 'react';\nimport { extend, ReactThreeFiber, useFrame, useThree } from 'react-three-fiber';\nimport { Vector3 } from 'three';\nimport { OrbitControls } from 'three/examples/jsm/controls/OrbitControls';\n\nextend({ OrbitControls });\n\ndeclare global {\n  namespace JSX {\n    interface IntrinsicElements {\n      orbitControls: ReactThreeFiber.Object3DNode<\n        OrbitControls,\n        typeof OrbitControls\n      >;\n    }\n  }\n}\n\nconst Controls: React.FC = () => {\n  const controls = useRef<OrbitControls>(null);\n  const { camera, gl } = useThree();\n\n  useFrame(() => controls.current?.update());\n\n  return (\n    <orbitControls\n      ref={controls}\n      args={[camera, gl.domElement]}\n      target={new Vector3(0, 1, 1)}\n      screenSpacePanning\n    />\n  );\n};\n\nexport default Controls;\n","import { FC, useEffect, useRef } from 'react';\nimport { Canvas } from 'react-three-fiber';\nimport useVRM from './hooks/useVRM';\nimport VRM from './components/VRM';\nimport './App.scss';\nimport CameraView from './components/CameraView';\nimport { loadFacemesh } from './utils/faces';\nimport Controls from './components/Controls';\nimport { loadPosenet } from './utils/poses';\n\nconst App: FC = () => {\n  const webcamRef = useRef(null);\n  const meshCanvasRef = useRef(null);\n  const [vrm, loadVRM] = useVRM();\n\n  const init = async () => {\n    loadVRM(\n      'https://raw.githubusercontent.com/mikezzb/OpenVTuber-js/master/public/vrms/AvatarSample_B.vrm'\n    );\n    loadFacemesh();\n    loadPosenet();\n    // await loadHandpose();\n  };\n\n  useEffect(() => {\n    init();\n  }, []);\n\n  return (\n    <div>\n      <Canvas\n        style={{\n          height: '100vh',\n          width: '100vw',\n        }}\n        pixelRatio={2}\n        className=\"fiber-canvas\"\n        camera={{\n          fov: 30,\n          near: 0.1,\n          far: 20,\n          position: [0, 1, 5],\n          zoom: 1.8,\n        }}\n      >\n        <color attach=\"background\" args={[0, 0, 0]} />\n        <directionalLight />\n        <VRM webcamRef={webcamRef} meshCanvasRef={meshCanvasRef} vrm={vrm} />\n        <Controls />\n      </Canvas>\n      <CameraView webcamRef={webcamRef} meshCanvasRef={meshCanvasRef} />\n    </div>\n  );\n};\n\nexport default App;\n","import { ReportHandler } from 'web-vitals';\n\nconst reportWebVitals = (onPerfEntry?: ReportHandler) => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.scss';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}