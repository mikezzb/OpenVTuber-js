{"version":3,"sources":["utils/faces.ts","utils/poses.ts","hooks/useVRM.ts","config.ts","utils/index.ts","components/VRM.tsx","components/CameraView.tsx","components/Controls.tsx","App.tsx","reportWebVitals.ts","index.tsx"],"names":["net","useVRM","loader","useRef","GLTFLoader","current","useState","vrm","setVRM","url","load","gltf","VRM","from","then","VRMUtils","removeUnnecessaryJoints","scene","rotateY","Math","PI","humanoid","getBoneNode","VRMSchema","HumanoidBoneName","LeftUpperArm","rotation","z","RightUpperArm","VIDEO_SIZE","DRAWING_COLOR","euclideanDistance","p1","p2","x","y","sqrt","drawLandmarks","ctx","r","beginPath","arc","fillStyle","fill","loadFacemesh","a","facemesh","mediapipeFacemesh","maxFaces","predictFace","input","estimateFaces","RIGHT_EYE_POINTS","LEFT_EYE_POINTS","LIPS_OPEN_SAMPLES","LIPS_OPEN_SAMPLES_LENGTH","length","face2quaternion","annotations","faces","silhouette","x1","THREE","fromArray","x2","y1","y2","xaxis","sub","normalize","yaxis","zaxis","crossVectors","mat","makeBasis","premultiply","makeRotationZ","setFromRotationMatrix","lipsOpenFactor","lowerKey","upperKey","samples","samplesLength","sum","forEach","index","lower","upper","getOpenFactor","getEyesOpen","scaledMesh","leftHorizDistance","leftVertDistance","right","left","FACES","faceGeo","drawPath","points","closePath","region","Path2D","moveTo","i","point","lineTo","strokeStyle","stroke","drawMesh","predictions","prediction","keypoints","map","loadPosenet","posenet","inputResolution","height","width","architecture","outputStride","predictPose","estimateSinglePose","getAngle","atan2","drawKeypoints","poseParts","keypoint","score","position","part","webcamRef","meshCanvasRef","prevState","face","angle","useFrame","delta","clock","mouse","video","readyState","Head","quaternion","slerp","blendShapeProxy","setValue","BlendShapePresetName","A","eyesOpen","BlinkL","BlinkR","videoWidth","videoHeight","getContext","leftShoulder","rightShoulder","Spine","leftElbow","leftWrist","RightLowerArm","rightElbow","rightWrist","LeftLowerArm","update","object","CameraView","onUserMediaError","e","alert","audio","className","ref","extend","OrbitControls","Controls","controls","useThree","camera","gl","args","domElement","target","Vector3","screenSpacePanning","App","loadVRM","init","useEffect","style","pixelRatio","fov","near","far","zoom","attach","reportWebVitals","onPerfEntry","Function","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"8+TAWIA,ECLAA,E,qGCuBWC,EAvBA,WACb,IAAiBC,EAAWC,iBAAO,IAAIC,KAA/BC,QACR,EAAsBC,mBAAqB,MAA3C,mBAAOC,EAAP,KAAYC,EAAZ,KAkBA,MAAO,CAACD,EAhBQ,SAACE,GACfP,EAAOQ,KAAKD,GAAK,SAAAE,GACfC,IAAIC,KAAKF,GAAMG,MAAK,SAAAP,GAClBQ,IAASC,wBAAwBL,EAAKM,OACtCV,EAAIU,MAAMC,QAAQC,KAAKC,IACvBb,EAAIc,SAASC,YACXC,IAAUC,iBAAiBC,cAC3BC,SAASC,EAbO,IAclBpB,EAAIc,SAASC,YACXC,IAAUC,iBAAiBI,eAC3BF,SAASC,GAhBO,IAiBlBnB,EAAOD,Y,kCCnBFsB,EACJ,IADIA,EAEH,IAGGC,EAAgB,OCDhBC,EAAoB,SAACC,EAAIC,GACpC,IAAMC,EAAID,EAAG,GAAKD,EAAG,GACfG,EAAIF,EAAG,GAAKD,EAAG,GACfL,EAAIM,EAAG,GAAKD,EAAG,GACrB,OAAOb,KAAKiB,KAAKF,EAAIA,EAAIC,EAAIA,EAAIR,EAAIA,IAqB1BU,EAAgB,SAACC,EAAKH,EAAGD,GAAc,IAAXK,EAAU,uDAAN,EAC3CD,EAAIE,YACJF,EAAIG,IAAIP,EAAGC,EAAGI,EAAG,EAAG,EAAIpB,KAAKC,IAC7BkB,EAAII,UAAYZ,EAChBQ,EAAIK,QJtBOC,EAAY,uCAAG,sBAAAC,EAAA,sEACdC,IAAcA,IAA2BC,kBAAmB,CACtEC,SAAU,IAFc,OAC1BhD,EAD0B,kDAAH,qDAMZiD,EAAW,uCAAG,WAAOC,GAAP,SAAAL,EAAA,0DACrB7C,EADqB,gCAEVA,EAAImD,cAAc,CAAED,UAFV,mFAAH,sDAQlBE,EAAmB,CAAC,IAAK,IAAK,IAAK,KACnCC,EAAkB,CAAC,IAAK,GAAI,IAAK,KAEjCC,EAAoB,CAAC,EAAG,EAAG,EAAG,GAC9BC,EAA2BD,EAAkBE,OAKtCC,EAAkB,SAAAC,GAC7B,IAAMC,EAAQD,EAAYE,WACpBC,GAAK,IAAIC,WAAgBC,UAAUJ,EAAM,IACzCK,GAAK,IAAIF,WAAgBC,UAAUJ,EAAM,KACzCM,GAAK,IAAIH,WAAgBC,UAAUJ,EAAM,KACzCO,GAAK,IAAIJ,WAAgBC,UAAUJ,EAAM,IACzCQ,EAAQH,EAAGI,IAAIP,GAAIQ,YACnBC,EAAQJ,EAAGE,IAAIH,GAAII,YACnBE,GAAQ,IAAIT,WAAgBU,aAAaL,EAAOG,GAChDG,GAAM,IAAIX,WACbY,UAAUP,EAAOG,EAAOC,GACxBI,aAAY,IAAIb,WAAgBc,cAAczD,KAAKC,KACtD,OAAO,IAAI0C,cAAmBe,sBAAsBJ,IAGzCK,EAAiB,SAAApB,GAAW,OItCZ,SAC3BA,EACAqB,EACAC,EACAC,EACAC,GAEA,IAAIC,EAAM,EAMV,OALAF,EAAQG,SAAQ,SAAAC,GACd,IAAMC,EAAQ5B,EAAYqB,GAAUM,GAlBxB,GAmBNE,EAAQ7B,EAAYsB,GAAUK,GAnBxB,GAoBZF,GAAOG,EAAQC,KAEVJ,EAAMD,EJ0BbM,CACE9B,EACA,iBACA,iBACAJ,EACAC,IAQSkC,EAAc,SAACC,GAC1B,IAAMC,EAAoB5D,EACxB2D,EAAWrC,EAAgB,IAC3BqC,EAAWrC,EAAgB,KAEvBuC,EAAmB7D,EACvB2D,EAAWrC,EAAgB,IAC3BqC,EAAWrC,EAAgB,KAY7B,MAAO,CACLwC,MAXyB9D,EACzB2D,EAAWtC,EAAiB,IAC5BsC,EAAWtC,EAAiB,MAOgB,EALpBrB,EACxB2D,EAAWtC,EAAiB,IAC5BsC,EAAWtC,EAAiB,MA9CL,GAoDvB0C,KAJqBH,GAAqB,EAAIC,GAhDvB,KA2DdG,EAAQC,EAEfC,EAAW,SAAC3D,EAAK4D,EAAQC,GAC7B,IAAMC,EAAS,IAAIC,OACnBD,EAAOE,OAAOJ,EAAO,GAAG,GAAIA,EAAO,GAAG,IACtC,IAAK,IAAIK,EAAI,EAAGA,EAAIL,EAAO1C,OAAQ+C,IAAK,CACtC,IAAMC,EAAQN,EAAOK,GACrBH,EAAOK,OAAOD,EAAM,GAAIA,EAAM,IAE5BL,GACFC,EAAOD,YAET7D,EAAIoE,YAAc,OAClBpE,EAAIqE,OAAOP,IAGAQ,EAAW,SAACC,EAAavE,IACrB,OAAXuE,QAAW,IAAXA,OAAA,EAAAA,EAAarD,QAAS,GACxBqD,EAAYzB,SAAQ,SAAA0B,GAElB,IADA,IAAMC,EAAYD,EAAWpB,WACpBa,EAAI,EAAGA,EAAIR,EAAMvC,OAAS,EAAG+C,IAAK,CACzC,IAAML,EAAS,CAACH,EAAU,EAAJQ,GAAQR,EAAU,EAAJQ,EAAQ,GAAIR,EAAU,EAAJQ,EAAQ,IAAIS,KAChE,SAAA3B,GAAK,OAAI0B,EAAU1B,MAErBY,EAAS3D,EAAK4D,GAAQ,GAExBa,EAAU3B,SAAQ,SAAAoB,GAChBnE,EAAcC,EAAKkE,EAAM,GAAIA,EAAM,GAAI,U,SC7GlCS,EAAW,uCAAG,sBAAApE,EAAA,sEACbqE,IAAa,CACvBC,gBAAiB,CACfC,OALQ,EAKAvF,EACRwF,MANQ,EAMDxF,GAETyF,aAAc,WACdC,aAAc,KAPS,OACzBvH,EADyB,kDAAH,qDAWXwH,EAAW,uCAAG,WAAOtE,GAAP,SAAAL,EAAA,0DACrB7C,EADqB,gCAEVA,EAAIyH,mBAAmBvE,GAFb,mFAAH,sDAQXwE,EAAW,SAACzF,EAAID,GAC3B,OAAOb,KAAKwG,MAAM1F,EAAGE,EAAIH,EAAGG,EAAGF,EAAGC,EAAIF,EAAGE,IAK9B0F,EAAgB,SAACb,EAA+BzE,GAC3D,IAAMuF,EAAY,GAWlB,OAVAd,EAAU3B,SAAQ,SAAA0C,GAChB,GAAIA,EAASC,MA/BM,IA+BkB,CACnC,MAAiBD,EAASE,SAAlB7F,EAAR,EAAQA,EAAGD,EAAX,EAAWA,EACX2F,EAAUC,EAASG,MAAQ,CACzB/F,EAAGL,EAAmBK,EACtBC,EAAGN,EAAoBM,GAEzBE,EAAcC,EApCN,EAoCWH,EApCX,EAoCsBD,OAG3B2F,G,QI4FMjH,EAxHQ,SAAC,GAAuC,IAArCL,EAAoC,EAApCA,IAAK2H,EAA+B,EAA/BA,UAAWC,EAAoB,EAApBA,cAClCC,EAAYjI,iBAGf,CAAEkI,KAAM,GAAIC,MAAO,KAiHtB,OA/GAC,YAAQ,uCAAC,aAAyBC,GAAzB,6CAAA3F,EAAA,2DAAS4F,MAAT,EAAgBC,OAErBnI,GAC6B,qBAAtB2H,EAAU7H,SACK,OAAtB6H,EAAU7H,SAC6B,IAAvC6H,EAAU7H,QAAQsI,MAAMC,WALnB,iCAQqB3F,EAAYiF,EAAU7H,QAAQsI,OARnD,cAQC9B,EARD,UASU,UAAKA,EAAY,UAAjB,aAAI,EAAyBnD,eACpCA,EADiD,UAClCmD,EAAY,UADsB,aACnC,EAAyBnD,YAE7CnD,EAAIc,SACDC,YAAYC,IAAUC,iBAAiBqH,MACvCC,WAAWC,MAAMtF,EAAgBC,GAAc,IAElDnD,EAAIyI,gBAAgBC,SAClB1H,IAAU2H,qBAAqBC,EAC/BrE,EAAepB,IAGX0F,EAAW3D,EAAYoB,EAAY,GAAGnB,YAC5CnF,EAAIyI,gBAAgBC,SAClB1H,IAAU2H,qBAAqBG,OAC/BD,EAAStD,KAAO,EAAI,GAEtBvF,EAAIyI,gBAAgBC,SAClB1H,IAAU2H,qBAAqBI,OAC/BF,EAASvD,MAAQ,EAAI,IAGnB0D,EAAarB,EAAU7H,QAAQsI,MAAMY,WACrCC,EAActB,EAAU7H,QAAQsI,MAAMa,YAC5CrB,EAAc9H,QAAQgH,MAAQkC,EAC9BpB,EAAc9H,QAAQ+G,OAASoC,EACzBlH,EAAM6F,EAAc9H,QAAQoJ,WAAW,MAC7C7C,EAASC,EAAavE,GApCjB,UA+CwBkF,EAAYU,EAAU7H,QAAQsI,OA/CtD,kDA+CiE,GA/CjE,gBA+CG5B,EA/CH,EA+CGA,cAEAc,EAAiBD,EAAcb,EAAWzE,IAElCoH,cAAgB7B,EAAU8B,eAExB,QADVrB,EAAQZ,EAASG,EAAU8B,cAAe9B,EAAU6B,iBAEtDpB,GAASA,EACTF,EAAU/H,QAAQiI,MAAMsB,MAAQtB,EAChC/H,EAAIc,SAASC,YACXC,IAAUC,iBAAiBoI,OAC3BlI,SAASC,EAAI2G,GAGfT,EAAU6B,cAAgB7B,EAAUgC,WAExB,QADVvB,EAAQZ,EAASG,EAAUgC,UAAWhC,EAAU6B,iBAElDpB,EAAQnH,KAAKC,GAAKkH,EAClBF,EAAU/H,QAAQiI,MAAM1G,cAAgB0G,EACxCA,GAAiBF,EAAU/H,QAAQiI,MAAMsB,OAAS,EAClDrJ,EAAIc,SAASC,YACXC,IAAUC,iBAAiBI,eAC3BF,SAASC,EAAI2G,GAGfT,EAAUiC,WAAajC,EAAUgC,WAErB,QADVvB,EAAQZ,EAASG,EAAUiC,UAAWjC,EAAUgC,cAElDvB,EAAQnH,KAAKC,GAAKkH,EAClBF,EAAU/H,QAAQiI,MAAMyB,cAAgBzB,EACxCA,GAAiBF,EAAU/H,QAAQiI,MAAM1G,eAAiB,EAC1DrB,EAAIc,SAASC,YACXC,IAAUC,iBAAiBuI,eAC3BrI,SAASC,EAAI2G,GAGfT,EAAU8B,eAAiB9B,EAAUmC,YAEzB,QADV1B,EAAQZ,EAASG,EAAUmC,WAAYnC,EAAU8B,kBAEnDrB,IAAiB,EACjBF,EAAU/H,QAAQiI,MAAM7G,aAAe6G,EACvCA,GAAiBF,EAAU/H,QAAQiI,MAAMsB,OAAS,EAClDrJ,EAAIc,SAASC,YACXC,IAAUC,iBAAiBC,cAC3BC,SAASC,EAAI2G,GAGfT,EAAUoC,YAAcpC,EAAUmC,YAEtB,QADV1B,EAAQZ,EAASG,EAAUoC,WAAYpC,EAAUmC,eAEnD1B,GAASA,EACTF,EAAU/H,QAAQiI,MAAM4B,aAAe5B,EACvCA,GAAiBF,EAAU/H,QAAQiI,MAAM7G,cAAgB,EACzDlB,EAAIc,SAASC,YACXC,IAAUC,iBAAiB0I,cAC3BxI,SAASC,EAAI2G,IAKrB/H,EAAI4J,OAAO3B,GA3GN,4CAAD,yDA+GDjI,GAAO,2BAAW6J,OAAQ7J,EAAIU,S,2BCzGxBoJ,G,OArBe,SAAC,GAAkC,IAAhCnC,EAA+B,EAA/BA,UAAWC,EAAoB,EAApBA,cAC1C,OACE,qCACE,cAAC,IAAD,CACEmC,iBAAkB,SAAAC,GAAC,OAAIC,MAAMD,IAC7BE,OAAO,EACPC,UAAU,eACVC,IAAKzC,EACLb,MAAOxF,EACPuF,OAAQvF,IAEV,wBACEwF,MAAOxF,EACPuF,OAAQvF,EACR6I,UAAU,kBACVC,IAAKxC,S,SCrBbyC,YAAO,CAAEC,oBAaT,IAgBeC,EAhBY,WACzB,IAAMC,EAAW5K,iBAAsB,MACvC,EAAuB6K,cAAfC,EAAR,EAAQA,OAAQC,EAAhB,EAAgBA,GAIhB,OAFA3C,aAAS,kCAAMwC,EAAS1K,eAAf,aAAM,EAAkB8J,YAG/B,+BACEQ,IAAKI,EACLI,KAAM,CAACF,EAAQC,EAAGE,YAClBC,OAAQ,IAAIC,UAAQ,EAAG,EAAG,GAC1BC,oBAAkB,KC0BTC,EA7CC,WACd,IAAMtD,EAAY/H,iBAAO,MACnBgI,EAAgBhI,iBAAO,MAC7B,EAAuBF,IAAvB,mBAAOM,EAAP,KAAYkL,EAAZ,KAEMC,EAAI,uCAAG,sBAAA7I,EAAA,6DACX4I,EACE,6HAFS,SAIL7I,IAJK,uBAKLqE,IALK,2CAAH,qDAaV,OAJA0E,qBAAU,WACRD,MACC,IAGD,gCACE,eAAC,IAAD,CACEE,MAAO,CACLxE,OAAQ,QACRC,MAAO,SAETwE,WAAY,EACZnB,UAAU,eACVO,OAAQ,CACNa,IAAK,GACLC,KAAM,GACNC,IAAK,GACLhE,SAAU,CAAC,EAAG,EAAG,GACjBiE,KAAM,KAZV,UAeE,uBAAOC,OAAO,aAAaf,KAAM,CAAC,EAAG,EAAG,KACxC,qCACA,cAAC,EAAD,CAAKjD,UAAWA,EAAWC,cAAeA,EAAe5H,IAAKA,IAC9D,cAAC,EAAD,OAEF,cAAC,EAAD,CAAY2H,UAAWA,EAAWC,cAAeA,QCpCxCgE,EAZS,SAACC,GACnBA,GAAeA,aAAuBC,UACxC,8BAAqBvL,MAAK,YAAkD,IAA/CwL,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOF,GACPG,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAQN,OCHdO,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1BZ,M","file":"static/js/main.6ff33e7d.chunk.js","sourcesContent":["import '@tensorflow/tfjs-backend-webgl';\nimport * as facemesh from '@tensorflow-models/face-landmarks-detection';\nimport { MediaPipeFaceMesh } from '@tensorflow-models/face-landmarks-detection/dist/mediapipe-facemesh';\n\nimport * as THREE from 'three';\nimport { Coord3D } from '@tensorflow-models/face-landmarks-detection/dist/mediapipe-facemesh/util';\nimport faceGeo from './faceGeo.json';\nimport { drawLandmarks, euclideanDistance, getOpenFactor } from '.';\n\n// MODEL\n\nlet net: MediaPipeFaceMesh;\n\nexport const loadFacemesh = async () => {\n  net = await facemesh.load(facemesh.SupportedPackages.mediapipeFacemesh, {\n    maxFaces: 1,\n  });\n};\n\nexport const predictFace = async (input: HTMLVideoElement) => {\n  if (net) {\n    return await net.estimateFaces({ input });\n  }\n};\n\n// VRM\n\nconst RIGHT_EYE_POINTS = [263, 362, 386, 374];\nconst LEFT_EYE_POINTS = [133, 33, 159, 145];\n\nconst LIPS_OPEN_SAMPLES = [0, 3, 6, 9];\nconst LIPS_OPEN_SAMPLES_LENGTH = LIPS_OPEN_SAMPLES.length;\nconst EYES_OPEN_SAMPLES = [0, 1, 2, 3, 4, 5, 6];\nconst EYES_OPEN_SAMPLES_LENGTH = EYES_OPEN_SAMPLES.length;\nconst CLOSE_EYE_BOUNDARY = 0.1;\n\nexport const face2quaternion = annotations => {\n  const faces = annotations.silhouette;\n  const x1 = new THREE.Vector3().fromArray(faces[9]);\n  const x2 = new THREE.Vector3().fromArray(faces[27]);\n  const y1 = new THREE.Vector3().fromArray(faces[18]);\n  const y2 = new THREE.Vector3().fromArray(faces[0]);\n  const xaxis = x2.sub(x1).normalize();\n  const yaxis = y2.sub(y1).normalize();\n  const zaxis = new THREE.Vector3().crossVectors(xaxis, yaxis);\n  const mat = new THREE.Matrix4()\n    .makeBasis(xaxis, yaxis, zaxis)\n    .premultiply(new THREE.Matrix4().makeRotationZ(Math.PI));\n  return new THREE.Quaternion().setFromRotationMatrix(mat);\n};\n\nexport const lipsOpenFactor = annotations =>\n  getOpenFactor(\n    annotations,\n    'lipsLowerInner',\n    'lipsUpperInner',\n    LIPS_OPEN_SAMPLES,\n    LIPS_OPEN_SAMPLES_LENGTH\n  );\n\ntype EyesOpen = {\n  left: boolean;\n  right: boolean;\n};\n\nexport const getEyesOpen = (scaledMesh: Coord3D[]): EyesOpen => {\n  const leftHorizDistance = euclideanDistance(\n    scaledMesh[LEFT_EYE_POINTS[2]],\n    scaledMesh[LEFT_EYE_POINTS[3]]\n  );\n  const leftVertDistance = euclideanDistance(\n    scaledMesh[LEFT_EYE_POINTS[0]],\n    scaledMesh[LEFT_EYE_POINTS[1]]\n  );\n  const rightHorizDistance = euclideanDistance(\n    scaledMesh[RIGHT_EYE_POINTS[2]],\n    scaledMesh[RIGHT_EYE_POINTS[3]]\n  );\n  const rightVertDistance = euclideanDistance(\n    scaledMesh[RIGHT_EYE_POINTS[0]],\n    scaledMesh[RIGHT_EYE_POINTS[1]]\n  );\n  const leftOpenFactor = leftHorizDistance / (2 * leftVertDistance);\n  const rightOpenFactor = rightHorizDistance / (2 * rightVertDistance);\n  return {\n    right: rightOpenFactor < CLOSE_EYE_BOUNDARY,\n    left: leftOpenFactor < CLOSE_EYE_BOUNDARY,\n  };\n};\n\n// CANVAS\n\n// https://github.com/spite/FaceMeshFaceGeometry/blob/master/js/geometry.js\nexport const FACES = faceGeo;\n\nconst drawPath = (ctx, points, closePath) => {\n  const region = new Path2D();\n  region.moveTo(points[0][0], points[0][1]);\n  for (let i = 1; i < points.length; i++) {\n    const point = points[i];\n    region.lineTo(point[0], point[1]);\n  }\n  if (closePath) {\n    region.closePath();\n  }\n  ctx.strokeStyle = 'grey';\n  ctx.stroke(region);\n};\n\nexport const drawMesh = (predictions, ctx) => {\n  if (predictions?.length > 0) {\n    predictions.forEach(prediction => {\n      const keypoints = prediction.scaledMesh;\n      for (let i = 0; i < FACES.length / 3; i++) {\n        const points = [FACES[i * 3], FACES[i * 3 + 1], FACES[i * 3 + 2]].map(\n          index => keypoints[index]\n        );\n        drawPath(ctx, points, true);\n      }\n      keypoints.forEach(point => {\n        drawLandmarks(ctx, point[1], point[0], 1);\n      });\n    });\n  }\n};\n","import * as posenet from '@tensorflow-models/posenet';\nimport { VIDEO_SIZE } from '../config';\nimport { drawLandmarks } from '.';\n\n// MODEL\n\nlet net: posenet.PoseNet;\n\nconst ADOPTION_POINT = 0.86;\nconst SCALE = 2;\n\nexport const loadPosenet = async () => {\n  net = await posenet.load({\n    inputResolution: {\n      height: VIDEO_SIZE.height * SCALE,\n      width: VIDEO_SIZE.width * SCALE,\n    },\n    architecture: 'ResNet50',\n    outputStride: 32,\n  });\n};\n\nexport const predictPose = async (input: HTMLVideoElement) => {\n  if (net) {\n    return await net.estimateSinglePose(input);\n  }\n};\n\n// VRM\n\nexport const getAngle = (p2, p1) => {\n  return Math.atan2(p2.y - p1.y, p2.x - p1.x);\n};\n\n// CANVAS\n\nexport const drawKeypoints = (keypoints: posenet.Keypoint[], ctx) => {\n  const poseParts = {};\n  keypoints.forEach(keypoint => {\n    if (keypoint.score > ADOPTION_POINT) {\n      const { y, x } = keypoint.position;\n      poseParts[keypoint.part] = {\n        x: VIDEO_SIZE.width - x,\n        y: VIDEO_SIZE.height - y,\n      };\n      drawLandmarks(ctx, y * SCALE, x * SCALE);\n    }\n  });\n  return poseParts;\n};\n","import { VRM, VRMSchema, VRMUtils } from '@pixiv/three-vrm';\nimport { useRef, useState } from 'react';\nimport { GLTFLoader } from 'three/examples/jsm/loaders/GLTFLoader';\n\nconst ARM_ROTATE_DEGREE = 1.2;\n\nconst useVRM = (): [VRM | null, (_: string) => void] => {\n  const { current: loader } = useRef(new GLTFLoader());\n  const [vrm, setVRM] = useState<VRM | null>(null);\n\n  const loadVRM = (url: string): void => {\n    loader.load(url, gltf => {\n      VRM.from(gltf).then(vrm => {\n        VRMUtils.removeUnnecessaryJoints(gltf.scene);\n        vrm.scene.rotateY(Math.PI);\n        vrm.humanoid.getBoneNode(\n          VRMSchema.HumanoidBoneName.LeftUpperArm\n        ).rotation.z = ARM_ROTATE_DEGREE;\n        vrm.humanoid.getBoneNode(\n          VRMSchema.HumanoidBoneName.RightUpperArm\n        ).rotation.z = -ARM_ROTATE_DEGREE;\n        setVRM(vrm);\n      });\n    });\n  };\n\n  return [vrm, loadVRM];\n};\n\nexport default useVRM;\n","export const DETECT_INTERVAL = 10;\n\nexport const VIDEO_SIZE = {\n  width: 320,\n  height: 240,\n};\n\nexport const DRAWING_COLOR = 'aqua';\n","import { DRAWING_COLOR } from '../config';\n\n// THREE\n\nconst Z_INDEX = 2;\n\nexport const euclideanDistance = (p1, p2) => {\n  const x = p2[0] - p1[0];\n  const y = p2[1] - p1[1];\n  const z = p2[2] - p1[2];\n  return Math.sqrt(x * x + y * y + z * z);\n};\n\nexport const getOpenFactor = (\n  annotations,\n  lowerKey: string,\n  upperKey: string,\n  samples: number[],\n  samplesLength: number\n) => {\n  let sum = 0;\n  samples.forEach(index => {\n    const lower = annotations[lowerKey][index][Z_INDEX];\n    const upper = annotations[upperKey][index][Z_INDEX];\n    sum += lower - upper;\n  });\n  return sum / samplesLength;\n};\n\n// CANVAS\n\nexport const drawLandmarks = (ctx, y, x, r = 3) => {\n  ctx.beginPath();\n  ctx.arc(x, y, r, 0, 2 * Math.PI);\n  ctx.fillStyle = DRAWING_COLOR;\n  ctx.fill();\n};\n","import { VRM as ThreeVRM, VRMSchema } from '@pixiv/three-vrm';\nimport { RefObject, useRef, FC } from 'react';\nimport { useFrame } from 'react-three-fiber';\nimport { AnnotatedPrediction } from '@tensorflow-models/face-landmarks-detection/dist/mediapipe-facemesh';\nimport Webcam from 'react-webcam';\nimport {\n  face2quaternion,\n  lipsOpenFactor,\n  drawMesh,\n  predictFace,\n  getEyesOpen,\n} from '../utils/faces';\nimport { drawKeypoints, getAngle, predictPose } from '../utils/poses';\n\ntype Props = {\n  vrm: ThreeVRM | null;\n  webcamRef: RefObject<Webcam>;\n  meshCanvasRef: RefObject<HTMLCanvasElement>;\n};\n\nconst VRM: FC<Props> = ({ vrm, webcamRef, meshCanvasRef }) => {\n  const prevState = useRef<{\n    face: AnnotatedPrediction[];\n    angle: Record<string, any>;\n  }>({ face: [], angle: {} });\n\n  useFrame(async ({ clock, mouse }, delta) => {\n    if (\n      vrm &&\n      typeof webcamRef.current !== 'undefined' &&\n      webcamRef.current !== null &&\n      webcamRef.current.video.readyState === 4\n    ) {\n      // Face Handling\n      const predictions = await predictFace(webcamRef.current.video);\n      if (predictions && (predictions[0] as any)?.annotations) {\n        const annotations = (predictions[0] as any)?.annotations;\n        // Head\n        vrm.humanoid\n          .getBoneNode(VRMSchema.HumanoidBoneName.Head)\n          .quaternion.slerp(face2quaternion(annotations), 0.1);\n        // Lips\n        vrm.blendShapeProxy.setValue(\n          VRMSchema.BlendShapePresetName.A,\n          lipsOpenFactor(annotations)\n        );\n        // Eyes\n        const eyesOpen = getEyesOpen(predictions[0].scaledMesh as any);\n        vrm.blendShapeProxy.setValue(\n          VRMSchema.BlendShapePresetName.BlinkL,\n          eyesOpen.left ? 1 : 0\n        );\n        vrm.blendShapeProxy.setValue(\n          VRMSchema.BlendShapePresetName.BlinkR,\n          eyesOpen.right ? 1 : 0\n        );\n      }\n      const videoWidth = webcamRef.current.video.videoWidth;\n      const videoHeight = webcamRef.current.video.videoHeight;\n      meshCanvasRef.current.width = videoWidth;\n      meshCanvasRef.current.height = videoHeight;\n      const ctx = meshCanvasRef.current.getContext('2d');\n      drawMesh(predictions, ctx);\n\n      // Hand Handling (DISABLED DUE TO ISSUE: https://github.com/tensorflow/tfjs/issues/2942)\n      /*\n      const handPredictions = await predictHands(webcamRef.current.video);\n      if (handPredictions) {\n        drawHands(handPredictions, ctx);\n      }\n      */\n\n      // Pose Handling\n      const { keypoints } = (await predictPose(webcamRef.current.video)) || {};\n      if (keypoints) {\n        const poseParts: any = drawKeypoints(keypoints, ctx);\n\n        if (poseParts.leftShoulder && poseParts.rightShoulder) {\n          let angle = getAngle(poseParts.rightShoulder, poseParts.leftShoulder);\n          if (angle !== null) {\n            angle = -angle;\n            prevState.current.angle.Spine = angle;\n            vrm.humanoid.getBoneNode(\n              VRMSchema.HumanoidBoneName.Spine\n            ).rotation.z = angle;\n          }\n        }\n        if (poseParts.leftShoulder && poseParts.leftElbow) {\n          let angle = getAngle(poseParts.leftElbow, poseParts.leftShoulder);\n          if (angle !== null) {\n            angle = Math.PI - angle;\n            prevState.current.angle.RightUpperArm = angle;\n            angle = angle - (prevState.current.angle.Spine || 0);\n            vrm.humanoid.getBoneNode(\n              VRMSchema.HumanoidBoneName.RightUpperArm\n            ).rotation.z = angle;\n          }\n        }\n        if (poseParts.leftWrist && poseParts.leftElbow) {\n          let angle = getAngle(poseParts.leftWrist, poseParts.leftElbow);\n          if (angle !== null) {\n            angle = Math.PI - angle;\n            prevState.current.angle.RightLowerArm = angle;\n            angle = angle - (prevState.current.angle.RightUpperArm || 0);\n            vrm.humanoid.getBoneNode(\n              VRMSchema.HumanoidBoneName.RightLowerArm\n            ).rotation.z = angle;\n          }\n        }\n        if (poseParts.rightShoulder && poseParts.rightElbow) {\n          let angle = getAngle(poseParts.rightElbow, poseParts.rightShoulder);\n          if (angle !== null) {\n            angle = angle * -1;\n            prevState.current.angle.LeftUpperArm = angle;\n            angle = angle - (prevState.current.angle.Spine || 0);\n            vrm.humanoid.getBoneNode(\n              VRMSchema.HumanoidBoneName.LeftUpperArm\n            ).rotation.z = angle;\n          }\n        }\n        if (poseParts.rightWrist && poseParts.rightElbow) {\n          let angle = getAngle(poseParts.rightWrist, poseParts.rightElbow);\n          if (angle !== null) {\n            angle = -angle;\n            prevState.current.angle.LeftLowerArm = angle;\n            angle = angle - (prevState.current.angle.LeftUpperArm || 0);\n            vrm.humanoid.getBoneNode(\n              VRMSchema.HumanoidBoneName.LeftLowerArm\n            ).rotation.z = angle;\n          }\n        }\n      }\n\n      vrm.update(delta);\n    }\n  });\n\n  return vrm && <primitive object={vrm.scene} />;\n};\n\nexport default VRM;\n","import { FC, RefObject } from 'react';\nimport '@tensorflow/tfjs-backend-webgl';\nimport Webcam from 'react-webcam';\nimport './CameraView.scss';\nimport { VIDEO_SIZE } from '../config';\n\ntype Props = {\n  webcamRef: RefObject<Webcam>;\n  meshCanvasRef: RefObject<HTMLCanvasElement>;\n};\n\nconst CameraView: FC<Props> = ({ webcamRef, meshCanvasRef }) => {\n  return (\n    <>\n      <Webcam\n        onUserMediaError={e => alert(e)}\n        audio={false}\n        className=\"webcam-video\"\n        ref={webcamRef}\n        width={VIDEO_SIZE.width}\n        height={VIDEO_SIZE.height}\n      />\n      <canvas\n        width={VIDEO_SIZE.width}\n        height={VIDEO_SIZE.height}\n        className=\"facemesh-canvas\"\n        ref={meshCanvasRef}\n      />\n    </>\n  );\n};\n\nexport default CameraView;\n","import React, { useRef } from 'react';\nimport { extend, ReactThreeFiber, useFrame, useThree } from 'react-three-fiber';\nimport { Vector3 } from 'three';\nimport { OrbitControls } from 'three/examples/jsm/controls/OrbitControls';\n\nextend({ OrbitControls });\n\ndeclare global {\n  namespace JSX {\n    interface IntrinsicElements {\n      orbitControls: ReactThreeFiber.Object3DNode<\n        OrbitControls,\n        typeof OrbitControls\n      >;\n    }\n  }\n}\n\nconst Controls: React.FC = () => {\n  const controls = useRef<OrbitControls>(null);\n  const { camera, gl } = useThree();\n\n  useFrame(() => controls.current?.update());\n\n  return (\n    <orbitControls\n      ref={controls}\n      args={[camera, gl.domElement]}\n      target={new Vector3(0, 1, 1)}\n      screenSpacePanning\n    />\n  );\n};\n\nexport default Controls;\n","import { FC, useEffect, useRef } from 'react';\nimport { Canvas } from 'react-three-fiber';\nimport useVRM from './hooks/useVRM';\nimport VRM from './components/VRM';\nimport './App.scss';\nimport CameraView from './components/CameraView';\nimport { loadFacemesh } from './utils/faces';\nimport Controls from './components/Controls';\nimport { loadPosenet } from './utils/poses';\n\nconst App: FC = () => {\n  const webcamRef = useRef(null);\n  const meshCanvasRef = useRef(null);\n  const [vrm, loadVRM] = useVRM();\n\n  const init = async () => {\n    loadVRM(\n      'https://raw.githubusercontent.com/mikezzb/kibou/master/public/vrms/AvatarSample_B.vrm?token=AFSVMPBOMNLNEITIUBH75DDBKKZUM'\n    );\n    await loadFacemesh();\n    await loadPosenet();\n    // await loadHandpose();\n  };\n\n  useEffect(() => {\n    init();\n  }, []);\n\n  return (\n    <div>\n      <Canvas\n        style={{\n          height: '100vh',\n          width: '100vw',\n        }}\n        pixelRatio={2}\n        className=\"fiber-canvas\"\n        camera={{\n          fov: 30,\n          near: 0.1,\n          far: 20,\n          position: [0, 1, 5],\n          zoom: 1.8,\n        }}\n      >\n        <color attach=\"background\" args={[0, 0, 0]} />\n        <directionalLight />\n        <VRM webcamRef={webcamRef} meshCanvasRef={meshCanvasRef} vrm={vrm} />\n        <Controls />\n      </Canvas>\n      <CameraView webcamRef={webcamRef} meshCanvasRef={meshCanvasRef} />\n    </div>\n  );\n};\n\nexport default App;\n","import { ReportHandler } from 'web-vitals';\n\nconst reportWebVitals = (onPerfEntry?: ReportHandler) => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.scss';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}